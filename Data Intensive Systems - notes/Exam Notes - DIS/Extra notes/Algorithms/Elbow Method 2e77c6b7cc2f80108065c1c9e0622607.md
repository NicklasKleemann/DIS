# Elbow Method

## Elbow Method

### Term definition table

| Term | Definition |
| --- | --- |
| Elbow Method | A **model selection technique** used to choose the optimal number of clusters KKK for K-Means. |
| K | Number of clusters. |
| Inertia | Sum of squared distances between points and their assigned cluster centroids. |
| Distortion | Another name for inertia or within-cluster variance. |
| Elbow Point | The value of K where improvement sharply decreases. |
| Over-clustering | Using too many clusters. |
| Under-clustering | Using too few clusters. |

---

### Definition about the algorithm

The **Elbow Method** helps determine the best number of clusters by running K-Means for different values of K and plotting the **inertia**.

The best K is found where the decrease in inertia starts to slow down — forming an **“elbow”** in the curve.

---

### Advantages / disadvantages

**Advantages**

- Simple and intuitive.
- No need for labels.
- Works well for K-Means.

**Disadvantages**

- Elbow point is sometimes ambiguous.
- Not reliable if clusters overlap.
- Does not guarantee best clustering quality.

---

### Math equation

### Inertia

$J(K) = \sum_{k=1}^{K} \sum_{x \in C_k} \|x - \mu_k\|^2$

---

### Runtime

Let:

- n = data points
- d = features
- $K_{max}$ = max clusters tested
- i = iterations

**Total runtime**

$O(K_{max} \cdot n \cdot K \cdot d \cdot i)$

---

### Python-like pseudo code

```python
defelbow_method(X, K_max):
    distortions = []

for kinrange(1, K_max +1):
        centroids, clusters = k_means(X, k)
        distortions.append(inertia(X, centroids, clusters))

    plot(range(1, K_max +1), distortions)
```

---

### Step-by-step through the method

1. Choose a maximum number of clusters.
2. Run K-Means for K = 1 to Kmax.
3. Compute inertia for each K.
4. Plot K vs inertia.
5. Find the “elbow” where the decrease slows.
6. Choose that K as optimal.